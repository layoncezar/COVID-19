{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPt9gu7tehWy8Qcj/sIo+GY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/layoncezar/COVID-19/blob/master/TCC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "R9U8ljNWupKt",
        "outputId": "c973e103-ad7c-44b0-aeab-ae8614ce8422"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-1-3e5c40c3c666>\"\u001b[0;36m, line \u001b[0;32m8\u001b[0m\n\u001b[0;31m    options(rgl.debug = TRUE)\u001b[0m\n\u001b[0m            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m expression cannot contain assignment, perhaps you meant \"==\"?\n"
          ]
        }
      ],
      "source": [
        "#Definindo a amostra\n",
        "pacotes <- c(\"plotly\",\"tidyverse\",\"ggrepel\",\"fastDummies\",\"knitr\",\"kableExtra\",\n",
        "             \"splines\",\"reshape2\",\"PerformanceAnalytics\",\"correlation\",\"see\",\n",
        "             \"ggraph\",\"psych\",\"nortest\",\"rgl\",\"car\",\"ggside\",\"tidyquant\",\"olsrr\",\n",
        "             \"jtools\",\"ggstance\",\"magick\",\"cowplot\",\"emojifont\",\"beepr\",\"Rcpp\",\n",
        "             \"equatiomatic\")\n",
        "\n",
        "options(rgl.debug = TRUE)\n",
        "\n",
        "if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){\n",
        "  instalador <- pacotes[!pacotes %in% installed.packages()]\n",
        "  for(i in 1:length(instalador)) {\n",
        "    install.packages(instalador, dependencies = T)\n",
        "    break()}\n",
        "  sapply(pacotes, require, character = T) \n",
        "} else {\n",
        "  sapply(pacotes, require, character = T) \n",
        "}\n",
        "\n",
        "\n",
        "# dados de morados\n",
        "Morador<-readRDS(\"MORADOR.rds\")\n",
        "\n",
        "#Criando um id para cada linha\n",
        "#id<-cod_upa*100+num_dom\n",
        "id<-Morador$COD_UPA*100+Morador$NUM_DOM\n",
        "id<-as.data.frame(id)\n",
        "\n",
        "#Contando quantos ids estão duplicados e qual é o número de ids(pessoas) por domicílio\n",
        "\n",
        "df_unique <- subset(id, !duplicated(id))\n",
        "table(id)\n",
        "\n",
        "df_count <- id %>% group_by(id) %>% summarize(count = n())\n",
        "\n",
        "#Base que fica com o id\n",
        "Base_morador<-transmute(Morador, id, UF, TIPO_SITUACAO_REG, V0403, V0404, V0405, V0409, V0410,\n",
        "                        V0411, V0413, V0306,ANOS_ESTUDO, RENDA_TOTAL, PC_RENDA_DISP)\n",
        "\n",
        "#Juntando as bases com base no id comum no intuito de inserir a quantidade de moradores por id\n",
        "#Juntando as duas bases\n",
        "Base_morador2<-merge(Base_morador, df_count, by.x=\"id\")\n",
        "\n",
        "#Apenas dados do chefe de família\n",
        "BaseMorador3<-Base_morador2[Base_morador2$V0306==1, ]\n",
        "\n",
        "#Apenas dados quanti\n",
        "BaseMoradorQuanti<-select(BaseMorador3, \"V0403\", \"V0409\", \"V0410\", \"V0411\",\n",
        "                          \"V0413\", \"ANOS_ESTUDO\", \"PC_RENDA_DISP\", \"count\")\n",
        "\n",
        "#Correlação entre variáveis\n",
        "library(corrplot)\n",
        "a<-cor(BaseMoradorQuanti, method = c(\"pearson\"))\n",
        "corrplot(a, method = \"number\")\n",
        "\n",
        "#Conclusão inicial: Baixa correlação entre as variáveis\n",
        "\n",
        "#############A base acima é a base total com dados quali e quanti apenas relacionados ao morador####\n",
        "\n",
        "### Extraindo dados de consumo alimentar #####\n",
        "#Leitura dos dados em rds\n",
        "Consumo<-readRDS(\"CONSUMO_ALIMENTAR.rds\")\n",
        "\n",
        "#Selecionando variáveis\n",
        "Consumo_select<-select(Consumo, \"UF\", \"TIPO_SITUACAO_REG\", \n",
        "                       \"COD_UPA\", \"NUM_DOM\", \"V9001\",\"QTD\", \"PESO_FINAL\")\n",
        "\n",
        "#Se eu for usar uma análise discriminante ou regressão logística aqui eu devo criar\n",
        "#uma nova base de dados. Considerando o consumo ou não. Daqui para baixo é só de\n",
        "#consumidores de café\n",
        "\n",
        "#Apenas Café \n",
        "Consumo_cafe<-Consumo_select[Consumo_select$V9001>=8501302 & Consumo_select$V9001<=8501311,]\n",
        "dim(Consumo_cafe)\n",
        "valores<-Consumo_cafe$V9001\n",
        "valores<-as.data.frame(valores)\n",
        "summary(valores)\n",
        "rotulos<-c(\"Cafe\", \"Cafe com Leite\", \"Cafe espresso\", \"Capuccino\", \"Capuccino Desc\", \n",
        "           \"Capuccino Light\", \"Carioca\", \"Cafe sub Leite\", \"Cafe Desc\", \"Cafe esp Desc\")\n",
        "\n",
        "\n",
        "fator_coluna <- factor(valores, levels = 8501302:8501311, labels = rotulos)\n",
        "fator_coluna<-as.data.frame(fator_coluna)\n",
        "summary(fator_coluna)\n",
        "tabelacafe<-table(fator_coluna)\n",
        "tabelacafe<-as.data.frame(tabelacafe)\n",
        "\n",
        "install.packages(\"treemap\")\n",
        "library(treemap)\n",
        "treemap(tabelacafe, \n",
        "        index = \"fator_coluna\", \n",
        "        vSize = \"Freq\", \n",
        "        type = \"index\", \n",
        "        title = \"Meu Gráfico Treemap\")\n",
        "\n",
        "\n",
        "\n",
        "#Criando um id para cada linha\n",
        "#id<-cod_upa*100+num_dom\n",
        "id2<-Consumo_cafe$COD_UPA*100+Consumo_cafe$NUM_DOM\n",
        "id2<-as.data.frame(id2)\n",
        "\n",
        "\n",
        "#Juntando o id ao Bando de Dados\n",
        "#O transmute permite selecionar as bases que serão mantidas ou não e a nova coluna a ser incorporada\n",
        "Base_c<-transmute(Consumo_cafe,id2, UF, TIPO_SITUACAO_REG, V9001,QTD, PESO_FINAL)\n",
        "#Usa essa Base_C (daqui para frente) para separar os demais grupos de consumidores\n",
        "\n",
        "#juntando a base a partir da soma da quantidade de cada família\n",
        "\n",
        "#reduzir id pela soma de todas as variáveis\n",
        "dados_reduzidos <- aggregate(QTD ~ id2, data = Base_c, FUN = sum)\n",
        "\n",
        "#Juntando o peso a dados reduzidos\n",
        "Base_Peso<-transmute(Base_c, id2, PESO_FINAL)\n",
        "dim(Base_Peso)\n",
        "\n",
        "#Aqui eu só tenho as variáveis que vou usar na regressão geral (Quantidade). Se eu for usar os dados de cada grupo de \n",
        "#produto, eu tenho que usar os códigos de cada tipo de café\n",
        "\n",
        "#Juntando as duas bases\n",
        "BaseGeral<- merge(BaseMorador3,dados_reduzidos, by.x = \"id\", by.y = \"id2\")\n",
        "Geral2<- merge(BaseGeral, Base_Peso, by.x = \"id\", by.y = \"id2\")\n",
        "dim(BaseGeral)\n",
        "\n",
        "#Incluindo o peso final\n",
        "library(dplyr)\n",
        "Base_Final <- Geral2 %>% \n",
        "  group_by(id, PESO_FINAL) %>% \n",
        "  distinct() %>% \n",
        "  ungroup()\n",
        "\n",
        "#Mudando o nome das variáveis\n",
        "names(Base_Final)<-c(\"id\", \"UF\", \"TIPO_SITUACAO_REG\",\"Idade_chefe\", \"Sexo_chefe\",\n",
        "                     \"Cor_Chefe\", \"Qtd_cartao\", \"Qtd_CC\", \"Qtd_cheque\", \"Qtd_poup\", \"ref_UC\", \n",
        "                     \"Anos_estudo\", \"Renda_total\", \"Renda_per_c\", \"Qtd_morador\", \"Qtd_Cons\", \"PESO\")\n",
        "sum(Base_Final$PESO)\n",
        "dim(Base_Final)\n",
        "summary(Base_Final)\n",
        "\n",
        "#--------------------------------------------------------------------------------\n",
        "#Análise de cluster\n",
        "#------------------Análise de Cluster por K-means----------\n",
        "#instalar pacotes\n",
        "install.packages(\"FactorMineR\")\n",
        "install.packages(\"factoextra\")\n",
        "install.packages(\"cluster\")\n",
        "install.packages(\"openxlsx\")\n",
        "install.packages(\"readxl\")\n",
        "install.packages(\"AER\")\n",
        "install.packages(\"writexl\")\n",
        "\n",
        "#Chamar os pacotes\n",
        "library(FactoMineR)\n",
        "library(factoextra)\n",
        "library(cluster)\n",
        "library(openxlsx)\n",
        "library(readxl)\n",
        "library(AER)\n",
        "library(writexl)\n",
        "\n",
        "\n",
        "#Base sem Z-score e sem dados faltantes #Base a ser incorporado os clusters\n",
        "dados_gerais<-na.omit(QuantiRaiz)\n",
        "dados_gerais<-as.data.frame(dados_gerais)\n",
        "\n",
        "#Estatística descritiva dos dados\n",
        "summary(dados_gerais)\n",
        "table(dados_gerais$TIPO_SITUACAO_REG)\n",
        "prop.table(table(dados_gerais$Cor_Chefe))\n",
        "sd(dados_gerais$Qtd_Cons)\n",
        "dados_gerais$Qtd_Cons<-exp(dados_gerais$Qtd_Cons)\n",
        "\n",
        "#Transformar em Escala e identificar outliers e remover NA\n",
        "z_score<-scale(QuantiCluster2)\n",
        "summary(z_score)\n",
        "\n",
        "#(dados faltantes) \n",
        "dados_brutos<-na.omit(z_score)\n",
        "dados_brutos<-as.data.frame(dados_brutos)\n",
        "\n",
        "#Verificando a presença de outliers\n",
        "boxplot(dados_brutos)\n",
        "summary(dados_brutos)\n",
        "\n",
        "#Definir a quantidade de Cluster\n",
        "fviz_nbclust(dados_brutos, kmeans, method = \"silhouette\")\n",
        "fviz_nbclust(dados_brutos, kmeans, method = \"gap_stat\")\n",
        "fviz_nbclust(dados_brutos, kmeans, method = \"wss\")\n",
        "\n",
        "# Número ótimo de clusters\n",
        "library(factoextra)\n",
        "\n",
        "fviz_nbclust(dados_brutos, kmeans, method = \"wss\")+\n",
        "  geom_vline(xintercept = 4, linetype = 2)\n",
        "\n",
        "#Gerar Kmeans\n",
        "dados_kmeans<-kmeans(dados_brutos, 2)\n",
        "dados_kmeans2<-kmeans(dados_brutos, 3)\n",
        "\n",
        "#Visualizacao do grafico\n",
        "fviz_cluster(dados_kmeans, data=dados_brutos, ellipse.type = \"euclid\", geom = \"point\")\n",
        "fviz_cluster(dados_kmeans2, data=dados_brutos, ellipse.type = \"euclid\", geom = c(\"point\", \"text\") )\n",
        "?fviz_cluster\n",
        "\n",
        "#criando uma lista com o cluster\n",
        "lista<-dados_kmeans$cluster\n",
        "lista\n",
        "\n",
        "#Agrupando em uma tabela\n",
        "dados_gerais<-cbind(dados_gerais,lista)\n",
        "dim(dados_gerais)\n",
        "\n",
        "#Analisando as características de cada cluster\n",
        "#Lista 1\n",
        "Lista1<-subset(dados_gerais, dados_gerais$lista==\"1\")\n",
        "dim(Lista1)\n",
        "Lista1$Qtd_Cons<-exp(Lista1$Qtd_Cons)\n",
        "\n",
        "summary(Lista1)\n",
        "\n",
        "#Lista 2\n",
        "Lista2<- subset(dados_gerais, dados_gerais$lista==\"2\")\n",
        "dim(Lista2)\n",
        "Lista2$Qtd_Cons<-exp(Lista2$Qtd_Cons)\n",
        "summary(Lista2)\n",
        "\n",
        "\n",
        "#Exportando as tabelas em csv\n",
        "\n",
        "write.table(dados_gerais, \"c:saida.csv\", sep=\",\" )\n",
        "write_xlsx(dados_gerais, \"c:saida.xlsx\")\n",
        "\n",
        "\n",
        "#--------------------------------------------------------\n",
        "#Regressão Geral\n",
        "#Pacotes da regressao\n",
        "pacotes <- c(\"plotly\",\"tidyverse\",\"ggrepel\",\"fastDummies\",\"knitr\",\"kableExtra\",\n",
        "             \"splines\",\"reshape2\",\"PerformanceAnalytics\",\"correlation\",\"see\",\n",
        "             \"ggraph\",\"psych\",\"nortest\",\"rgl\",\"car\",\"ggside\",\"tidyquant\",\"olsrr\",\n",
        "             \"jtools\",\"ggstance\",\"magick\",\"cowplot\",\"emojifont\",\"beepr\",\"Rcpp\",\n",
        "             \"equatiomatic\")\n",
        "\n",
        "options(rgl.debug = TRUE)\n",
        "\n",
        "if(sum(as.numeric(!pacotes %in% installed.packages())) != 0){\n",
        "  instalador <- pacotes[!pacotes %in% installed.packages()]\n",
        "  for(i in 1:length(instalador)) {\n",
        "    install.packages(instalador, dependencies = T)\n",
        "    break()}\n",
        "  sapply(pacotes, require, character = T) \n",
        "} else {\n",
        "  sapply(pacotes, require, character = T) \n",
        "}\n",
        "\n",
        "#Removendo colunas específicas\n",
        "dados_gerais$Qtd_Cons<- exp(dados_gerais$Qtd_Cons)\n",
        "dados <- subset(dados_gerais, select = -c(Renda_total))\n",
        "\n",
        "#Verificar normalidade da variável dependente\n",
        "hist(dados$Qtd_Cons)\n",
        "\n",
        "#Como não é normal vou realizar uma transformação de box-cox\n",
        "#Para calcular o lambda de Box-Cox\n",
        "#função 'powerTransform' do pacote 'car'\n",
        "lambda_BC <- powerTransform(dados$Qtd_Cons)\n",
        "lambda_BC\n",
        "\n",
        "#Inserindo o lambda de Box-Cox na base de dados para a estimação de um novo modelo\n",
        "dados$Qtd_Cons <- (((dados$Qtd_Cons ^ lambda_BC$lambda) - 1) / \n",
        "                     lambda_BC$lambda)\n",
        "\n",
        "#Verificar normalidade novamente\n",
        "hist(dados$Qtd_Cons)\n",
        "\n",
        "#Testando os modelos\n",
        "Modelo2<-lm(Qtd_Cons~., data=dados)\n",
        "summary(Modelo2)\n",
        "\n",
        "#Aplicando log em renda per capita\n",
        "dados$Renda_per_c<-log(dados$Renda_per_c)\n",
        "hist(dados$Renda_per_c)\n",
        "dados2<-na.omit(dados)\n",
        "dim(dados)\n",
        "summary(dados2)\n",
        "\n",
        "#Novo Modelo\n",
        "ModeloNA<-lm(Qtd_Cons~., data=dados2)\n",
        "summary(ModeloNA)\n",
        "\n",
        "#Verificando os resíduos do modelo\n",
        "residuos <- residuals(Modelo2)\n",
        "sd_residuos <- sd(residuos)\n",
        "limite_superior <- mean(residuos) + 3 * sd_residuos\n",
        "limite_inferior <- mean(residuos) - 3 * sd_residuos\n",
        "outliers <- which(residuos > limite_superior | residuos < limite_inferior)\n",
        "print(outliers)\n",
        "\n",
        "#Normalidade\n",
        "library(nortest)\n",
        "res<-ModeloNA$residuals\n",
        "qqnorm(res)\n",
        "qqline(res)\n",
        "hist(ModeloNA$residuals)\n",
        "#OK, Distribuição normal agora\n",
        "\n",
        "#Heterocedasticidade\n",
        "ols_test_breusch_pagan(ModeloNA)\n",
        "\n",
        "#Passo 1 dumizar\n",
        "dummy1<-dummy_columns(.data = dados2,\n",
        "                      select_columns = \"UF\",\n",
        "                      remove_selected_columns = T,\n",
        "                      remove_most_frequent_dummy = T)\n",
        "dummy2<-dummy_columns(.data = dummy1,\n",
        "                      select_columns = \"TIPO_SITUACAO_REG\",\n",
        "                      remove_selected_columns = T,\n",
        "                      remove_most_frequent_dummy = T)\n",
        "dummy3<-dummy_columns(.data = dummy2,\n",
        "                      select_columns = \"Sexo_chefe\",\n",
        "                      remove_selected_columns = T,\n",
        "                      remove_most_frequent_dummy = T)\n",
        "dummy4<-dummy_columns(.data = dummy3,\n",
        "                      select_columns = \"Cor_Chefe\",\n",
        "                      remove_selected_columns = T,\n",
        "                      remove_most_frequent_dummy = T)\n",
        "\n",
        "#Modelo após dumizadação\n",
        "Modelodumizado<-lm(Qtd_Cons~., data=dummy4)\n",
        "summary(Modelodumizado)\n",
        "\n",
        "#Após a identificação dos outliers deve-se excluir as linhas\n",
        "linhas_para_excluir <- c(446, 445, 502, 501, 1484, 1482, 1823, 1821, 1898,\n",
        "                         1896, 2043, 2041, 2063, 2061, 4314, 4310, 4659, 4655,\n",
        "                         4818, 4814, 6057, 6049)\n",
        "\n",
        "# excluir as linhas do dataframe\n",
        "df_sem_linhas <- subset(dummy4, !row.names(dummy4) %in% linhas_para_excluir)\n",
        "print(df_sem_linhas)\n",
        "\n",
        "#Rodando outro modelo com esse novo dataset\n",
        "Modelodf<-lm(Qtd_Cons~., data=df_sem_linhas)\n",
        "summary(Modelodf)\n",
        "\n",
        "#Verificando heterocedasticidade no modelo\n",
        "ols_test_breusch_pagan(Modelodf)\n",
        "boxplot(df_sem_linhas)\n",
        "\n",
        "#Verificando Multicolinearidade\n",
        "ols_vif_tol(Modelodf)\n",
        "\n",
        "#Gráfico de resíduos\n",
        "residuos <- Modelodf$residuals\n",
        "valores_ajustados <- Modelodf$fitted.values\n",
        "plot(valores_ajustados, residuos, main = \"Gráfico de Resíduos vs. Valores Ajustados\", \n",
        "     xlab = \"Valores Ajustados\", ylab = \"Resíduos\")\n",
        "\n",
        "abline(h = 0, col = \"red\")\n",
        "title(xlab = \"Valores Ajustados\", ylab = \"Resíduos\")\n",
        "\n",
        "\n",
        "#Stepwise\n",
        "step_modelo_bc <- step(Modelodf, k = 3.841459)\n",
        "summary(step_modelo_bc)\n",
        "\n",
        "#Melhor modelo agora é esse chamado Modelodf\n",
        "\n",
        "#Visualizando a equação da regressão\n",
        "extract_eq(step_modelo_bc, use_coefs = T) %>%\n",
        "  kable() %>%\n",
        "  kable_styling(bootstrap_options = \"striped\",\n",
        "                full_width = F,\n",
        "                font_size = 10)\n",
        "\n",
        "#Outras maneiras de apresentar os outputs do modelo\n",
        "#função 'summ' do pacote 'jtools'\n",
        "\n",
        "ap1<-summ(Modelodf, confint = T, digits = 4, ci.width = .95)\n",
        "ap1<-tidy(ap1)\n",
        "ap2<-summ(step_modelo_bc, confint = T, digits = 4, ci.width = .95)\n",
        "ap2<-tidy(ap2)\n",
        "\n",
        "#Comparando modelos\n",
        "export_summs(Modelodf, step_modelo_bc, scale=F)\n",
        "\n",
        "#Visualizando a equação da regressão\n",
        "extract_eq(step_modelo_bc, use_coefs = T) %>%\n",
        "  kable() %>%\n",
        "  kable_styling(bootstrap_options = \"striped\",\n",
        "                full_width = F,\n",
        "                font_size = 20\n",
        "  )\n",
        "\n",
        "# exportar o dataframe como um arquivo xlsx\n",
        "library(openxlsx)\n",
        "\n",
        "write.xlsx(ap1, \"ap1.xlsx\")\n",
        "write.xlsx(ap2, \"ap2.xlsx\")\n",
        "\n",
        "#Deu certo!!!!!\n",
        "\n",
        "#Citação do R no TCC\n",
        "citation()\n",
        "#---------------------------------------------------------"
      ]
    }
  ]
}